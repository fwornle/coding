{
  "id": "snapshot_1762235904258_gvoj6kqgn",
  "approvalId": "approval_1762235904252_k14klixxm",
  "approvalTitle": "Extended Requirements: 5 Teams (RaaS, ReSi, Coding, Agentic, UI)",
  "version": 1,
  "timestamp": "2025-11-04T05:58:24.258Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Requirements: Ontology-Based Knowledge Management for Cluster Reprocessing\n\n**Feature ID**: `ONTO-001`\n**Priority**: High\n**Status**: Draft\n**Created**: 2025-01-03\n**Domain**: Knowledge Management, Vehicle Data Reprocessing\n\n---\n\n## Executive Summary\n\nIntegrate a configurable ontology system into the StreamingKnowledgeExtractor to capture and organize domain knowledge across multiple domains. The system shall support an upper ontology representing the Cluster Reprocessing (RPR) domain and team-specific lower ontologies for five teams:\n\n- **RaaS Team**: Cloud orchestration for vehicle data reprocessing\n- **ReSi Team**: Virtual target development for embedded ADAS functions\n- **Coding Team**: Knowledge management infrastructure (LSL, constraints, trajectory, MCP)\n- **Agentic Team**: AI agent frameworks, RAG systems, and communication protocols\n- **UI Team**: Multi-agent curriculum alignment system with AWS serverless architecture\n\nThe ontology system enables domain-specific knowledge classification, semantic queries, and team-scoped knowledge retrieval.\n\n---\n\n## 1. Business Context\n\n### 1.1 Problem Statement\n\nThe current knowledge management system lacks domain structure for vehicle data reprocessing concepts. Knowledge is classified into generic types (coding_pattern, bug_solution, etc.) without understanding reprocessing-specific entities like:\n- Recorded sensor data and trace formats\n- Virtual targets and RPUs (Reprocessing Units)\n- Data quality frameworks and KPI evaluation\n- Orchestration workflows and cloud infrastructure\n\nThis limits:\n- Discoverability of reprocessing-specific knowledge\n- Cross-team knowledge sharing between RaaS and ReSi\n- Semantic queries about domain concepts\n- Integration with team-specific tooling and workflows\n\n### 1.2 Stakeholders\n\n| Stakeholder | Interest | Impact |\n|------------|----------|--------|\n| RaaS Team (Java/Cloud) | Cloud orchestration knowledge capture | High |\n| ReSi Team (C++/Embedded) | Virtual target development patterns | High |\n| Data Engineers | Data format and quality knowledge | Medium |\n| Function Developers | ADAS function validation patterns | Medium |\n| Knowledge Management System | Ontology infrastructure | High |\n\n### 1.3 Success Criteria\n\n1. **Domain Coverage**: Ontology covers ≥80% of core reprocessing concepts\n2. **Classification Accuracy**: ≥85% of knowledge correctly classified to ontology classes\n3. **Team Adoption**: Both RaaS and ReSi teams using team-specific ontologies\n4. **Query Improvement**: 50% improvement in semantic query precision for domain concepts\n5. **Performance**: <100ms overhead for ontology classification per knowledge extraction\n\n---\n\n## 2. Domain Analysis: Cluster Reprocessing (RPR)\n\n### 2.1 Domain Overview\n\n**Cluster Reprocessing** is the ecosystem of tools and services for replaying vehicle-recorded sensor and ECU data through virtual targets to validate ADAS/AD functions.\n\n**Core Process Flow**:\n```\nRecorded Data → Normalization → Reprocessing → KPI Computation → Safety Assessment (SOTIF)\n```\n\n**Execution Contexts**:\n- **Local Reprocessing**: Developer machines for rapid iteration\n- **Cloud Reprocessing**: Petabyte-scale validation in AWS using Kubernetes\n\n### 2.2 Key Domain Concepts\n\n#### 2.2.1 Data Layer\n\n**RecordedData**:\n- **Sources**: Sensor data (camera, radar, lidar), SOME/IP traces, MIPI camera streams\n- **Container Formats**:\n  - MF4 (recording format on embedded target, may be fragmented)\n  - MCAP (normalized data processing format)\n- **Payload Formats**:\n  - Protobuf/SPP (Serialized Protobuf Protocol)\n  - Kaitai-described binary blobs (architecture/compiler-specific)\n- **Metadata**: JSON\n- **Storage**: S3 buckets (cloud), local filesystem (dev)\n\n**Data Quality**:\n- R-DQ (RaaS Data Quality) framework validates data fitness\n- Configurable quality criteria via YAML\n- Only sufficient-quality data is reprocessed\n\n**Data Normalization**:\n- Unfragments MF4 data\n- Converts to Protobuf/SPP encoding\n- Outputs to MCAP container format\n- Handles architecture-specific binary blobs\n\n#### 2.2.2 Reprocessing Layer\n\n**Virtual Target**:\n- Software representation of vehicle ECU\n- Reads from trace files, writes outputs to trace files\n- Runs locally (developer) or in cloud (validation)\n\n**RPU (Reprocessing Unit)**:\n- Dockerized virtual target\n- Orchestrated on Kubernetes cluster\n- Stored in Artifactory binary server\n- Versioned for reproducibility\n\n**Compound Reprocessing**:\n- Entire sensor + AD-ECU system in DAG\n- Coordinated multi-RPU execution\n- Managed by Argo Workflows\n\n#### 2.2.3 Orchestration Layer (RaaS)\n\n**RaaS (Reprocessing as a Service)**:\n- Java-based orchestration engine\n- Event-based data mesh architecture on AWS\n- REST API for configuration submission\n- Manages:\n  - RPU scheduling on Kubernetes\n  - Data set selection for reprocessing\n  - Version management for RPUs\n  - Workflow execution via Argo\n\n**Configuration**:\n- YAML-based declarative configs\n- Specifies: datasets, RPU versions, execution parameters\n- Posted via REST endpoints\n\n**Monitoring & Observability**:\n- Prometheus for metrics collection\n- Grafana dashboards for visualization\n- FinOps (Financial Operations) monitoring\n\n**Data Caching**:\n- Performance optimization for repeated processing\n- Intermediate result storage\n\n#### 2.2.4 Evaluation Layer\n\n**KPI Framework**:\n- Triggering layer around RaaS\n- Python-based evaluation scripts (Dockerized)\n- Processes:\n  - Signal extraction from reprocessed outputs\n  - KPI computation for function fitness\n  - Safety assessment (SOTIF compliance)\n- Configuration specifies:\n  - Interval sets for reprocessing\n  - KPI docker container versions\n  - Evaluation criteria\n\n**SOTIF (Safety of the Intended Functionality)**:\n- Validates function behavior meets safety requirements\n- Assesses false positives/negatives\n- Endurance run analysis\n\n#### 2.2.5 Function Validation Domains\n\n**ADAS Functions**:\n- AEB (Automatic Emergency Braking)\n- Road marking detection\n- Obstacle detection\n- Lane keeping assistance\n- Adaptive cruise control\n\n---\n\n## 3. Upper Ontology: Cluster Reprocessing (RPR)\n\n### 3.1 Entity Classes\n\n```yaml\n# Upper Ontology: \"cluster-reprocessing\" (cluster-rpr)\nversion: \"1.0.0\"\ndomain: \"Vehicle Data Reprocessing & ADAS Validation\"\n\nentities:\n\n  # ============================================================================\n  # DATA DOMAIN\n  # ============================================================================\n\n  RecordedData:\n    description: \"Vehicle-recorded sensor and ECU data\"\n    properties:\n      sources:\n        type: \"array\"\n        items: [\"camera\", \"radar\", \"lidar\", \"SOME/IP\", \"MIPI\"]\n      containerFormat:\n        type: \"enum\"\n        values: [\"MF4\", \"MCAP\"]\n      payloadFormat:\n        type: \"enum\"\n        values: [\"Protobuf/SPP\", \"Kaitai-Binary\"]\n      metadata:\n        type: \"JSON\"\n      duration:\n        type: \"number\"\n        unit: \"seconds\"\n      fragmented:\n        type: \"boolean\"\n        description: \"Whether data is fragmented (common in MF4)\"\n      storageLocation:\n        type: \"enum\"\n        values: [\"S3\", \"Local\"]\n      dataQuality:\n        type: \"number\"\n        min: 0.0\n        max: 1.0\n\n  DataSet:\n    description: \"Collection of RecordedData for testing/validation\"\n    properties:\n      name: { type: \"string\" }\n      purpose:\n        type: \"enum\"\n        values: [\"endurance-run\", \"scenario-specific\", \"regression\", \"validation\"]\n      recordingCount: { type: \"number\" }\n      totalSize: { type: \"number\", unit: \"bytes\" }\n      qualityCriteria: { type: \"JSON\" }\n\n  DataQualityMetric:\n    description: \"Measures data fitness for reprocessing\"\n    properties:\n      metricType:\n        type: \"enum\"\n        values: [\"completeness\", \"accuracy\", \"consistency\", \"temporal-alignment\"]\n      threshold: { type: \"number\" }\n      evaluationResult: { type: \"boolean\" }\n\n  NormalizationLayer:\n    description: \"Transforms fragmented/raw data to normalized format\"\n    properties:\n      inputFormat: { type: \"string\" }\n      outputFormat: { type: \"string\", default: \"SPP@MCAP\" }\n      transformations: { type: \"array\", items: \"string\" }\n\n  # ============================================================================\n  # REPROCESSING DOMAIN\n  # ============================================================================\n\n  VirtualTarget:\n    description: \"Software representation of vehicle ECU\"\n    properties:\n      ecuType:\n        type: \"enum\"\n        values: [\"AD-ECU\", \"ADAS-ECU\", \"Perception-ECU\", \"Planning-ECU\"]\n      architecture:\n        type: \"enum\"\n        values: [\"x86-64\", \"ARM64\"]\n      sourceCodeVersion: { type: \"string\" }\n      runtimeEnvironment:\n        type: \"enum\"\n        values: [\"local\", \"cloud\"]\n      includesMiddleware: { type: \"boolean\", default: false }\n\n  RPU:\n    description: \"Reprocessing Unit - Dockerized virtual target\"\n    properties:\n      imageId: { type: \"string\" }\n      imageTag: { type: \"string\" }\n      artifactoryPath: { type: \"string\" }\n      virtualTarget: { type: \"reference\", to: \"VirtualTarget\" }\n      resourceRequirements:\n        cpu: { type: \"string\", example: \"2000m\" }\n        memory: { type: \"string\", example: \"4Gi\" }\n\n  CompoundReprocessing:\n    description: \"Entire sensor + ECU system in execution DAG\"\n    properties:\n      rpuComponents: { type: \"array\", items: \"reference-to-RPU\" }\n      dagDefinition: { type: \"JSON\" }\n      executionMode:\n        type: \"enum\"\n        values: [\"sequential\", \"parallel\", \"hybrid\"]\n\n  ReprocessingExecution:\n    description: \"Instance of reprocessing run\"\n    properties:\n      executionId: { type: \"string\" }\n      dataset: { type: \"reference\", to: \"DataSet\" }\n      rpu: { type: \"reference\", to: \"RPU\" }\n      status:\n        type: \"enum\"\n        values: [\"pending\", \"running\", \"completed\", \"failed\"]\n      startTime: { type: \"ISO8601\" }\n      endTime: { type: \"ISO8601\" }\n      outputLocation: { type: \"string\" }\n\n  # ============================================================================\n  # ORCHESTRATION DOMAIN\n  # ============================================================================\n\n  OrchestrationEngine:\n    description: \"System managing reprocessing execution\"\n    properties:\n      engineType:\n        type: \"enum\"\n        values: [\"RaaS\", \"LocalOrchestrator\"]\n      architecture:\n        type: \"string\"\n        example: \"event-based-data-mesh\"\n\n  WorkflowDefinition:\n    description: \"Argo Workflow for reprocessing orchestration\"\n    properties:\n      workflowType:\n        type: \"enum\"\n        values: [\"compound-reprocessing\", \"single-rpu\", \"kpi-evaluation\"]\n      argoYaml: { type: \"string\" }\n      dependencies: { type: \"array\", items: \"string\" }\n\n  KubernetesResource:\n    description: \"K8s resources for execution\"\n    properties:\n      resourceType:\n        type: \"enum\"\n        values: [\"Pod\", \"Job\", \"Deployment\", \"Service\"]\n      namespace: { type: \"string\" }\n      resourceYaml: { type: \"string\" }\n\n  ConfigurationFile:\n    description: \"YAML configuration for reprocessing/KPI\"\n    properties:\n      configType:\n        type: \"enum\"\n        values: [\"reprocessing\", \"kpi-evaluation\", \"data-quality\", \"finops\"]\n      yamlContent: { type: \"string\" }\n      submissionEndpoint: { type: \"string\" }\n\n  # ============================================================================\n  # EVALUATION DOMAIN\n  # ============================================================================\n\n  KPIFramework:\n    description: \"Triggering layer around RaaS for evaluation\"\n    properties:\n      intervalSets: { type: \"array\", items: \"reference-to-DataSet\" }\n      kpiContainerVersion: { type: \"string\" }\n      evaluationScript: { type: \"string\" }\n\n  KPIScript:\n    description: \"Dockerized Python evaluation script\"\n    properties:\n      scriptName: { type: \"string\" }\n      language: { type: \"string\", default: \"Python\" }\n      dockerImage: { type: \"string\" }\n      functionTarget:\n        type: \"enum\"\n        values: [\"AEB\", \"RoadMarking\", \"ObstacleDetection\", \"LaneKeeping\", \"ACC\"]\n\n  SignalExtraction:\n    description: \"Extracts signals from reprocessed data for KPI computation\"\n    properties:\n      signalNames: { type: \"array\", items: \"string\" }\n      extractionMethod: { type: \"string\" }\n      outputFormat: { type: \"string\" }\n\n  SOTIFAssessment:\n    description: \"Safety of Intended Functionality validation\"\n    properties:\n      functionName: { type: \"string\" }\n      falsePositives: { type: \"number\" }\n      falseNegatives: { type: \"number\" }\n      safetyRequirementsMet: { type: \"boolean\" }\n      enduranceRunAnalysis: { type: \"JSON\" }\n\n  # ============================================================================\n  # INFRASTRUCTURE DOMAIN\n  # ============================================================================\n\n  ArtifactoryServer:\n    description: \"Binary repository for RPU images\"\n    properties:\n      serverUrl: { type: \"string\" }\n      repositories: { type: \"array\", items: \"string\" }\n\n  MonitoringSystem:\n    description: \"Observability infrastructure\"\n    properties:\n      systemType:\n        type: \"enum\"\n        values: [\"Prometheus\", \"Grafana\", \"CloudWatch\"]\n      metrics: { type: \"array\", items: \"string\" }\n\n  DataCache:\n    description: \"Performance optimization cache\"\n    properties:\n      cacheType:\n        type: \"enum\"\n        values: [\"intermediate-results\", \"normalized-data\", \"kpi-outputs\"]\n      storageTier:\n        type: \"enum\"\n        values: [\"memory\", \"ssd\", \"s3\"]\n      ttl: { type: \"number\", unit: \"seconds\" }\n\n  FinOps:\n    description: \"Financial operations and cost optimization\"\n    properties:\n      costCenter: { type: \"string\" }\n      budgetLimit: { type: \"number\", unit: \"USD\" }\n      costOptimizationRules: { type: \"array\", items: \"JSON\" }\n\nrelationships:\n  # Data relationships\n  contains: { from: \"DataSet\", to: \"RecordedData\", cardinality: \"one-to-many\" }\n  validates: { from: \"DataQualityMetric\", to: \"RecordedData\", cardinality: \"many-to-one\" }\n  normalizes: { from: \"NormalizationLayer\", to: \"RecordedData\", cardinality: \"one-to-many\" }\n  produces: { from: \"NormalizationLayer\", to: \"RecordedData\", cardinality: \"one-to-many\" }\n\n  # Reprocessing relationships\n  implements: { from: \"RPU\", to: \"VirtualTarget\", cardinality: \"many-to-one\" }\n  includes: { from: \"CompoundReprocessing\", to: \"RPU\", cardinality: \"one-to-many\" }\n  executes: { from: \"ReprocessingExecution\", to: \"RPU\", cardinality: \"many-to-one\" }\n  processes: { from: \"ReprocessingExecution\", to: \"DataSet\", cardinality: \"many-to-one\" }\n\n  # Orchestration relationships\n  orchestrates: { from: \"OrchestrationEngine\", to: \"WorkflowDefinition\", cardinality: \"one-to-many\" }\n  schedules: { from: \"WorkflowDefinition\", to: \"KubernetesResource\", cardinality: \"one-to-many\" }\n  runsOn: { from: \"RPU\", to: \"KubernetesResource\", cardinality: \"many-to-one\" }\n  configuredBy: { from: \"ReprocessingExecution\", to: \"ConfigurationFile\", cardinality: \"many-to-one\" }\n\n  # Evaluation relationships\n  triggers: { from: \"KPIFramework\", to: \"ReprocessingExecution\", cardinality: \"one-to-many\" }\n  evaluates: { from: \"KPIScript\", to: \"ReprocessingExecution\", cardinality: \"many-to-one\" }\n  extracts: { from: \"SignalExtraction\", to: \"RecordedData\", cardinality: \"many-to-many\" }\n  assesses: { from: \"SOTIFAssessment\", to: \"KPIScript\", cardinality: \"one-to-one\" }\n\n  # Infrastructure relationships\n  stores: { from: \"ArtifactoryServer\", to: \"RPU\", cardinality: \"one-to-many\" }\n  monitors: { from: \"MonitoringSystem\", to: \"ReprocessingExecution\", cardinality: \"one-to-many\" }\n  caches: { from: \"DataCache\", to: \"RecordedData\", cardinality: \"many-to-many\" }\n  optimizes: { from: \"FinOps\", to: \"ReprocessingExecution\", cardinality: \"one-to-many\" }\n```\n\n---\n\n## 4. Lower Ontology: RaaS Team (Cloud Orchestration)\n\n### 4.1 Team Context\n\n**Team**: RaaS (Reprocessing as a Service)\n**Focus**: Petabyte-scale cloud orchestration, data quality, FinOps\n**Tech Stack**: Java, AWS, Kubernetes, Argo Workflows, Prometheus, Grafana\n**Architecture**: Event-based data mesh\n\n### 4.2 Entity Classes\n\n```yaml\n# Lower Ontology: \"raas\"\nextends: \"cluster-reprocessing\"\nversion: \"1.0.0\"\nteam: \"RaaS\"\n\nentities:\n\n  # ============================================================================\n  # CLOUD ORCHESTRATION\n  # ============================================================================\n\n  EventMeshNode:\n    description: \"Node in event-based data mesh architecture\"\n    properties:\n      nodeType:\n        type: \"enum\"\n        values: [\"producer\", \"consumer\", \"processor\", \"router\"]\n      eventTopics: { type: \"array\", items: \"string\" }\n      javaServiceClass: { type: \"string\" }\n\n  ArgoWorkflowTemplate:\n    description: \"Reusable Argo workflow template\"\n    properties:\n      templateName: { type: \"string\" }\n      steps: { type: \"array\", items: \"JSON\" }\n      parameters: { type: \"JSON\" }\n      retryPolicy: { type: \"JSON\" }\n\n  KubernetesCluster:\n    description: \"K8s cluster for RPU execution\"\n    properties:\n      clusterName: { type: \"string\" }\n      region: { type: \"string\", example: \"us-east-1\" }\n      nodeGroups: { type: \"array\", items: \"JSON\" }\n      scalingPolicy: { type: \"JSON\" }\n\n  RESTEndpoint:\n    description: \"Configuration submission endpoint\"\n    properties:\n      endpoint: { type: \"string\" }\n      httpMethod:\n        type: \"enum\"\n        values: [\"POST\", \"PUT\", \"GET\", \"DELETE\"]\n      requestSchema: { type: \"JSON\" }\n      authentication: { type: \"string\" }\n\n  # ============================================================================\n  # DATA QUALITY & CACHING\n  # ============================================================================\n\n  RDQFramework:\n    description: \"RaaS Data Quality validation framework\"\n    properties:\n      qualityRules: { type: \"array\", items: \"JSON\" }\n      yamlConfigPath: { type: \"string\" }\n      validationStrategy:\n        type: \"enum\"\n        values: [\"pre-reprocessing\", \"post-normalization\", \"continuous\"]\n\n  CachingStrategy:\n    description: \"Data/result caching for performance\"\n    properties:\n      strategyType:\n        type: \"enum\"\n        values: [\"read-through\", \"write-through\", \"lazy-loading\"]\n      cacheTiers:\n        type: \"array\"\n        items: { type: \"enum\", values: [\"memory\", \"ssd\", \"s3\"] }\n      evictionPolicy:\n        type: \"enum\"\n        values: [\"LRU\", \"LFU\", \"TTL\"]\n\n  # ============================================================================\n  # MONITORING & FINOPS\n  # ============================================================================\n\n  PrometheusMetric:\n    description: \"Prometheus metric definition\"\n    properties:\n      metricName: { type: \"string\" }\n      metricType:\n        type: \"enum\"\n        values: [\"Counter\", \"Gauge\", \"Histogram\", \"Summary\"]\n      labels: { type: \"JSON\" }\n      scrapeInterval: { type: \"number\", unit: \"seconds\" }\n\n  GrafanaDashboard:\n    description: \"Grafana visualization dashboard\"\n    properties:\n      dashboardId: { type: \"string\" }\n      panels: { type: \"array\", items: \"JSON\" }\n      dataSource: { type: \"string\" }\n      refreshInterval: { type: \"number\", unit: \"seconds\" }\n\n  CostOptimizationRule:\n    description: \"FinOps cost reduction strategy\"\n    properties:\n      ruleName: { type: \"string\" }\n      trigger: { type: \"JSON\" }\n      action:\n        type: \"enum\"\n        values: [\"scale-down\", \"spot-instances\", \"data-tiering\", \"cache-pruning\"]\n      expectedSavings: { type: \"number\", unit: \"USD\" }\n\n  # ============================================================================\n  # KPI EVALUATION LAYER\n  # ============================================================================\n\n  IntervalSet:\n    description: \"Time intervals for KPI evaluation\"\n    properties:\n      intervalCount: { type: \"number\" }\n      intervalDuration: { type: \"number\", unit: \"seconds\" }\n      samplingStrategy:\n        type: \"enum\"\n        values: [\"continuous\", \"random\", \"scenario-based\"]\n\n  KPITrigger:\n    description: \"Trigger configuration for KPI evaluation\"\n    properties:\n      triggerCondition: { type: \"JSON\" }\n      targetKPIScript: { type: \"reference\", to: \"KPIScript\" }\n      priorityLevel:\n        type: \"enum\"\n        values: [\"low\", \"medium\", \"high\", \"critical\"]\n\nrelationships:\n  # RaaS-specific relationships\n  partOf: { from: \"EventMeshNode\", to: \"OrchestrationEngine\", cardinality: \"many-to-one\" }\n  instantiates: { from: \"ArgoWorkflowTemplate\", to: \"WorkflowDefinition\", cardinality: \"one-to-many\" }\n  runsOn: { from: \"WorkflowDefinition\", to: \"KubernetesCluster\", cardinality: \"many-to-one\" }\n  submitsTo: { from: \"ConfigurationFile\", to: \"RESTEndpoint\", cardinality: \"many-to-one\" }\n  validates: { from: \"RDQFramework\", to: \"DataSet\", cardinality: \"one-to-many\" }\n  appliesTo: { from: \"CachingStrategy\", to: \"DataCache\", cardinality: \"one-to-one\" }\n  collects: { from: \"PrometheusMetric\", to: \"ReprocessingExecution\", cardinality: \"many-to-many\" }\n  visualizes: { from: \"GrafanaDashboard\", to: \"PrometheusMetric\", cardinality: \"one-to-many\" }\n  applies: { from: \"CostOptimizationRule\", to: \"KubernetesCluster\", cardinality: \"many-to-one\" }\n  defines: { from: \"IntervalSet\", to: \"KPIFramework\", cardinality: \"many-to-one\" }\n```\n\n---\n\n## 5. Lower Ontology: ReSi Team (Virtual Target Development)\n\n### 5.1 Team Context\n\n**Team**: ReSi (Reprocessing Simulation)\n**Focus**: Virtual target development, data format handling, embedded C++ orchestration\n**Tech Stack**: C++, x86-64 architecture, MF4/MCAP, Protobuf/SPP\n**Domain**: Close to embedded target code, no vehicle middleware\n\n### 5.2 Entity Classes\n\n```yaml\n# Lower Ontology: \"resi\"\nextends: \"cluster-reprocessing\"\nversion: \"1.0.0\"\nteam: \"ReSi\"\n\nentities:\n\n  # ============================================================================\n  # EMBEDDED ORCHESTRATION\n  # ============================================================================\n\n  FunctionOrchestrator:\n    description: \"C++ orchestration layer for ECU functions\"\n    properties:\n      ecuTarget: { type: \"reference\", to: \"VirtualTarget\" }\n      orchestratedFunctions: { type: \"array\", items: \"string\" }\n      executionOrder: { type: \"array\", items: \"string\" }\n      timingConstraints: { type: \"JSON\" }\n\n  EmbeddedFunction:\n    description: \"Single ADAS/AD function implementation\"\n    properties:\n      functionName: { type: \"string\" }\n      sourceCodePath: { type: \"string\" }\n      cppStandard:\n        type: \"enum\"\n        values: [\"C++11\", \"C++14\", \"C++17\", \"C++20\"]\n      compilationFlags: { type: \"string\" }\n      memoryFootprint: { type: \"number\", unit: \"bytes\" }\n\n  # ============================================================================\n  # DATA FORMAT HANDLING\n  # ============================================================================\n\n  MF4Container:\n    description: \"MF4 recording format from embedded target\"\n    properties:\n      version:\n        type: \"enum\"\n        values: [\"4.0\", \"4.1\", \"4.2\"]\n      isFragmented: { type: \"boolean\" }\n      channels: { type: \"array\", items: \"JSON\" }\n      attachments: { type: \"array\", items: \"string\" }\n\n  MCAPContainer:\n    description: \"MCAP normalized data processing format\"\n    properties:\n      version: { type: \"string\" }\n      schema: { type: \"JSON\" }\n      compressionCodec:\n        type: \"enum\"\n        values: [\"none\", \"lz4\", \"zstd\"]\n      unfragmented: { type: \"boolean\", default: true }\n\n  ProtobufSPP:\n    description: \"Serialized Protobuf Protocol payload\"\n    properties:\n      protoSchema: { type: \"string\" }\n      sppVersion: { type: \"string\" }\n      messageTypes: { type: \"array\", items: \"string\" }\n\n  KaitaiBinaryBlob:\n    description: \"Architecture/compiler-specific binary data\"\n    properties:\n      kaitaiDefinition: { type: \"string\" }\n      architecture:\n        type: \"enum\"\n        values: [\"x86-64\", \"ARM32\", \"ARM64\", \"RISC-V\"]\n      compilerVersion: { type: \"string\" }\n      endianness:\n        type: \"enum\"\n        values: [\"little\", \"big\"]\n\n  DataSerializer:\n    description: \"Serialization logic for embedded target\"\n    properties:\n      serializationFormat: { type: \"string\" }\n      targetArchitecture: { type: \"string\" }\n      byteOrder: { type: \"string\" }\n\n  # ============================================================================\n  # NORMALIZATION LAYER\n  # ============================================================================\n\n  FragmentationHandler:\n    description: \"Handles MF4 data fragmentation\"\n    properties:\n      fragmentationType:\n        type: \"enum\"\n        values: [\"image\", \"video\", \"large-message\"]\n      reassemblyStrategy: { type: \"string\" }\n      bufferSize: { type: \"number\", unit: \"bytes\" }\n\n  FormatConverter:\n    description: \"Converts between data formats\"\n    properties:\n      sourceFormat: { type: \"string\" }\n      targetFormat: { type: \"string\", default: \"SPP@MCAP\" }\n      conversionRules: { type: \"JSON\" }\n      preservesMetadata: { type: \"boolean\" }\n\n  # ============================================================================\n  # TRACE FILE I/O\n  # ============================================================================\n\n  TraceFileReader:\n    description: \"Reads trace files for virtual target input\"\n    properties:\n      supportedFormats: { type: \"array\", items: \"string\" }\n      readStrategy:\n        type: \"enum\"\n        values: [\"sequential\", \"random-access\", \"streaming\"]\n      bufferingPolicy: { type: \"JSON\" }\n\n  TraceFileWriter:\n    description: \"Writes virtual target outputs to trace files\"\n    properties:\n      outputFormat: { type: \"string\" }\n      compressionEnabled: { type: \"boolean\" }\n      flushStrategy:\n        type: \"enum\"\n        values: [\"immediate\", \"buffered\", \"periodic\"]\n\n  # ============================================================================\n  # DEVELOPMENT ENVIRONMENT\n  # ============================================================================\n\n  LocalDevelopmentSetup:\n    description: \"Developer machine configuration for local reprocessing\"\n    properties:\n      osType:\n        type: \"enum\"\n        values: [\"Linux\", \"Windows\", \"macOS\"]\n      compilerToolchain: { type: \"string\", example: \"GCC-11\" }\n      localTraceFilePath: { type: \"string\" }\n      debuggerConfiguration: { type: \"JSON\" }\n\n  CompilationProfile:\n    description: \"Build configuration for virtual target\"\n    properties:\n      targetArch: { type: \"string\", default: \"x86-64\" }\n      optimizationLevel:\n        type: \"enum\"\n        values: [\"O0\", \"O1\", \"O2\", \"O3\", \"Os\"]\n      includesMiddleware: { type: \"boolean\", default: false }\n      linkage:\n        type: \"enum\"\n        values: [\"static\", \"dynamic\"]\n\n  # ============================================================================\n  # TIMING & SYNCHRONIZATION\n  # ============================================================================\n\n  TimingModel:\n    description: \"Real-time behavior model for virtual target\"\n    properties:\n      executionMode:\n        type: \"enum\"\n        values: [\"real-time\", \"as-fast-as-possible\", \"stepped\"]\n      clockSource: { type: \"string\" }\n      synchronizationStrategy: { type: \"JSON\" }\n\n  SOMEIPTrace:\n    description: \"SOME/IP protocol trace data\"\n    properties:\n      serviceId: { type: \"number\" }\n      methodId: { type: \"number\" }\n      messageType:\n        type: \"enum\"\n        values: [\"REQUEST\", \"RESPONSE\", \"EVENT\", \"ERROR\"]\n      payload: { type: \"binary\" }\n\nrelationships:\n  # ReSi-specific relationships\n  orchestrates: { from: \"FunctionOrchestrator\", to: \"EmbeddedFunction\", cardinality: \"one-to-many\" }\n  implements: { from: \"VirtualTarget\", to: \"FunctionOrchestrator\", cardinality: \"one-to-one\" }\n  containedIn: { from: \"RecordedData\", to: \"MF4Container\", cardinality: \"many-to-one\" }\n  producesFrom: { from: \"NormalizationLayer\", to: \"MF4Container\", cardinality: \"one-to-many\" }\n  outputsTo: { from: \"NormalizationLayer\", to: \"MCAPContainer\", cardinality: \"one-to-many\" }\n  encodedAs: { from: \"RecordedData\", to: \"ProtobufSPP\", cardinality: \"many-to-one\" }\n  describes: { from: \"KaitaiBinaryBlob\", to: \"RecordedData\", cardinality: \"one-to-many\" }\n  uses: { from: \"DataSerializer\", to: \"VirtualTarget\", cardinality: \"many-to-one\" }\n  handles: { from: \"FragmentationHandler\", to: \"MF4Container\", cardinality: \"one-to-many\" }\n  converts: { from: \"FormatConverter\", to: \"RecordedData\", cardinality: \"many-to-many\" }\n  reads: { from: \"TraceFileReader\", to: \"VirtualTarget\", cardinality: \"many-to-one\" }\n  writes: { from: \"TraceFileWriter\", to: \"VirtualTarget\", cardinality: \"many-to-one\" }\n  configures: { from: \"LocalDevelopmentSetup\", to: \"VirtualTarget\", cardinality: \"one-to-many\" }\n  buildsUsing: { from: \"VirtualTarget\", to: \"CompilationProfile\", cardinality: \"many-to-one\" }\n  appliesTo: { from: \"TimingModel\", to: \"VirtualTarget\", cardinality: \"one-to-one\" }\n```\n\n---\n\n## 6. Lower Ontology: Coding Team (Knowledge Management Infrastructure)\n\n### 6.1 Team Context\n\nThe **Coding Team** develops and maintains the knowledge management infrastructure for the coding project, including:\n- Live Session Logging (LSL) with 4-layer monitoring and 5-layer classification\n- Constraint Monitoring with 18 active constraints enforced via PreToolUse hooks\n- Trajectory Generation with real-time state tracking and MCP-powered analysis\n- Knowledge extraction, graph databases (Graphology + LevelDB), and vector search (Qdrant)\n- MCP integrations: Semantic Analysis (10 agents), Serena AST Analysis, Constraint Monitor\n\n### 6.2 Key Entity Classes\n\nThe coding lower ontology defines 18 entity classes extending the upper ontology:\n\n**Session Management**:\n- `LSLSession` - Live session logging with time-windowed conversation capture\n- `ClassificationLayer` - 5-layer classification system (session filter, path, keyword, embedding, semantic)\n- `TrajectoryState` - Real-time development trajectory states (exploring, implementing, verifying, etc.)\n\n**Quality & Constraints**:\n- `ConstraintRule` - Coding constraints with severity levels (critical, error, warning, info)\n- `HookConfiguration` - PreToolUse/PostToolUse hook definitions for enforcement and logging\n- `RedactionPattern` - Security patterns for sanitizing sensitive information\n\n**Knowledge Management**:\n- `KnowledgeEntity` - Graph nodes with observations and relationships\n- `EmbeddingVector` - 384-dim (local Transformers.js) or 1536-dim (OpenAI) embeddings\n- `GraphDatabase` - Graphology + LevelDB persistent graph storage\n- `VectorDatabase` - Qdrant collections for semantic similarity search\n\n**Infrastructure**:\n- `MonitoringLayer` - 4-layer monitoring architecture (watchdog, coordinator, verifier, service)\n- `MCPAgent` - Specialized agents in MCP Semantic Analysis Server (10 agents)\n- `WorkflowDefinition` - Multi-agent workflow coordination with step dependencies\n- `ConfigurationFile` - JSON/YAML configuration files for system components\n- `PlantUMLDiagram` - Architecture diagrams with standardized styling\n\n**Detailed Ontology**: See `.data/ontologies/lower/coding-ontology.json` for complete entity definitions, properties, and relationships.\n\n---\n\n## 7. Lower Ontology: Agentic Team (AI Agent Frameworks & RAG Systems)\n\n### 7.1 Team Context\n\nThe **Agentic Team** focuses on AI agent frameworks, RAG (Retrieval Augmented Generation) systems, and agent communication protocols through a 6-week nanodegree curriculum:\n- **Module 1**: Agent Frameworks (LangChain, LangGraph, CrewAI, PydanticAI, Atomic Agents, ADK, Agno)\n- **Module 2**: RAG Architecture (basic RAG, graph RAG, agentic RAG, multimodal RAG)\n- **Module 3**: Communication Protocols (MCP, ACP, A2A)\n- Cloud development environments with pre-configured workspaces and API access\n\n### 7.2 Key Entity Classes\n\nThe agentic lower ontology defines 15 entity classes extending the upper ontology:\n\n**Agent Frameworks**:\n- `AgentFramework` - AI agent libraries (LangChain, CrewAI, PydanticAI, etc.)\n- `PromptTemplate` - Reusable prompt templates (system, user, few-shot, chain-of-thought, ReAct)\n- `ToolDefinition` - Agent tool definitions for function calling\n- `AgentWorkflow` - Multi-agent coordination patterns (sequential, parallel, hierarchical, graph, swarm)\n\n**RAG Systems**:\n- `RAGSystem` - RAG architectures (basic, graph, agentic, multimodal)\n- `VectorStore` - Vector databases (Qdrant, Pinecone, Weaviate, ChromaDB, FAISS, Milvus)\n- `KnowledgeGraph` - Graph structures for graph RAG (Neo4j, Neptune, ArangoDB, NetworkX)\n- `EvaluationMetric` - RAG evaluation metrics (RAGAS, TruLens, LangSmith)\n\n**Communication & Orchestration**:\n- `CommunicationProtocol` - Agent protocols (MCP, ACP, A2A) with transport layers\n- `LLMProvider` - LLM service integrations (OpenAI, Anthropic, Groq, Google, AWS Bedrock)\n\n**Learning Resources**:\n- `CourseModule` - Week-long modules in 6-week program\n- `ModuleContent` - Learning materials (video, interactive notebooks, readings, labs, quizzes)\n- `Exercise` - Coding exercises with difficulty levels\n- `LabEnvironment` - Cloud development workspaces with pre-installed tools\n- `DevelopmentSetup` - Pre-configured environments (Python, Docker, dependencies)\n\n**Detailed Ontology**: See `.data/ontologies/lower/agentic-ontology.json` for complete entity definitions, properties, and relationships.\n\n---\n\n## 8. Lower Ontology: UI Team (Multi-Agent Curriculum Alignment System)\n\n### 8.1 Team Context\n\nThe **UI Team** develops the Multi-Agent Curriculum Alignment System (MACAS) for Central European University (CEU):\n- **8 Specialized Agents**: Coordinator, Web Search, Browser (Stagehand/MCP), Document Processing, Accreditation Expert, QA, Semantic Search, Chat Interface\n- **AWS Serverless**: Lambda functions, API Gateway, Step Functions, EventBridge, S3, CloudFront\n- **Databases**: PostgreSQL (Supabase/Neon), Qdrant vector database\n- **Frontend**: React 18 + Redux + Tailwind CSS + TypeScript\n- **Purpose**: Automate curriculum alignment, gap analysis, and peer university comparisons\n\n### 8.2 Key Entity Classes\n\nThe ui lower ontology defines 18 entity classes extending the upper ontology:\n\n**Multi-Agent System**:\n- `AgentInstance` - 8 specialized agents with configurable LLM models\n- `WorkflowOrchestration` - Multi-agent workflows (sequential, parallel, conditional, event-driven)\n- `LLMConfiguration` - Model selection per agent (OpenAI, Anthropic, Groq for cost optimization)\n\n**AWS Serverless Infrastructure**:\n- `AWSLambdaFunction` - Serverless compute (Node.js 20.x, Python 3.11)\n- `AWSStepFunction` - Workflow orchestration with ASL (Amazon States Language)\n- `APIGatewayEndpoint` - REST API endpoints with authentication (Cognito, API key, IAM)\n- `EventBridgeRule` - Event-driven triggers (S3 events, scheduled cron)\n- `S3Bucket` - File storage (document upload, report export, static assets, backup)\n- `CloudFrontDistribution` - CDN for frontend and API distribution\n\n**Data Management**:\n- `PostgreSQLSchema` - Database schemas (Supabase/Neon) for users, programs, courses, curricula\n- `QdrantCollection` - Vector collections for semantic search (configurable embedding models like Grok)\n- `DocumentParser` - Excel/Word/PDF processing with LLM enhancement\n- `CurriculumEntity` - Academic entities (courses, programs, learning outcomes, modules, assessments)\n\n**Frontend**:\n- `ReactComponent` - UI components (pages, containers, presentational, layout, utility)\n- `ReduxState` - State management slices (curriculum, analysis, loading states)\n- `TailwindStyle` - CEU brand theme (institutional colors, typography, responsive design)\n\n**Analysis & Reporting**:\n- `SemanticSearchQuery` - Natural language queries with vector embeddings and filters\n- `GapAnalysisReport` - Gap analysis and peer comparison reports (Excel, Word, PDF export)\n\n**Detailed Ontology**: See `.data/ontologies/lower/ui-ontology.json` for complete entity definitions, properties, and relationships.\n\n---\n\n## 9. Functional Requirements\n\n### FR-1: Ontology Management System\n\n**Priority**: MUST HAVE\n\n#### FR-1.1: Ontology Loading & Parsing\n- System SHALL load ontology definitions from JSON files\n- System SHALL support upper ontology and multiple lower ontologies\n- System SHALL resolve lower ontology inheritance from upper ontology\n- System SHALL validate ontology schema on load\n\n#### FR-1.2: Ontology Query API\n- System SHALL provide API to query entity types by ontology (upper/lower)\n- System SHALL provide API to query relationship types\n- System SHALL provide API to resolve team-specific ontology\n- System SHALL cache ontology lookups for performance\n\n#### FR-1.3: Ontology Validation\n- System SHALL validate entity properties against ontology schema\n- System SHALL support optional validation modes: strict, warning, disabled\n- System SHALL be configurable per team for validation strictness\n- System SHALL return validation results with errors and warnings\n\n---\n\n### FR-2: Knowledge Classification with Ontology\n\n**Priority**: MUST HAVE\n\n#### FR-2.1: LLM-Based Classification\n- StreamingKnowledgeExtractor SHALL classify knowledge using ontology classes\n- System SHALL use team context to resolve appropriate ontology (resi/raas)\n- System SHALL generate LLM prompts with ontology class definitions\n- System SHALL extract ontology properties from knowledge text\n\n#### FR-2.2: Confidence Scoring\n- System SHALL assign confidence score to ontology classification (0-1)\n- System SHALL require minimum confidence threshold (configurable, default 0.6)\n- System SHALL log low-confidence classifications for review\n\n#### FR-2.3: Fallback Strategy\n- System SHALL fall back to heuristic classification if LLM unavailable\n- System SHALL fall back to generic types if budget exceeded\n- System SHALL mark fallback classifications with source metadata\n\n---\n\n### FR-3: Graph Database Integration\n\n**Priority**: MUST HAVE\n\n#### FR-3.1: Enhanced Entity Storage\n- Graph database SHALL store ontology metadata in entity structure\n- Entity SHALL include ontology field with: domain, class, team, properties\n- System SHALL preserve backward compatibility with non-ontology entities\n\n#### FR-3.2: Ontology-Based Queries\n- System SHALL support queries filtering by ontology class\n- System SHALL support queries filtering by ontology properties\n- System SHALL support queries with team-specific ontology scope\n\n#### FR-3.3: Relationship Semantics\n- System SHALL support ontology-defined relationship types\n- System SHALL validate relationships against ontology schema (if enabled)\n- System SHALL allow traversing relationships by ontology type\n\n---\n\n### FR-4: Configuration System\n\n**Priority**: MUST HAVE\n\n#### FR-4.1: Ontology Configuration\n- System SHALL load configuration from `.specstory/config/ontology-config.json`\n- Configuration SHALL specify enabled/disabled state\n- Configuration SHALL specify default upper ontology\n- Configuration SHALL map teams to lower ontologies\n\n#### FR-4.2: Validation Configuration\n- Configuration SHALL specify validation mode per team\n- Configuration SHALL specify whether to fail on validation errors\n- Configuration SHALL allow disabling validation entirely\n\n#### FR-4.3: Classification Configuration\n- Configuration SHALL specify whether to use upper/lower ontologies\n- Configuration SHALL specify minimum confidence threshold\n- Configuration SHALL specify LLM budget allocation for classification\n\n---\n\n### FR-5: Query & Retrieval Enhancements\n\n**Priority**: SHOULD HAVE\n\n#### FR-5.1: Ontology-Aware Search\n- KnowledgeRetriever SHALL support searching by ontology class\n- KnowledgeRetriever SHALL support filtering by ontology properties\n- KnowledgeRetriever SHALL support semantic search with ontology context\n\n#### FR-5.2: Related Entity Discovery\n- System SHALL support finding entities related by ontology relationships\n- System SHALL support graph traversal with ontology relationship types\n- System SHALL support depth-limited traversal with ontology filters\n\n---\n\n## 10. Non-Functional Requirements\n\n### NFR-1: Performance\n\n- Ontology classification SHALL add <100ms overhead per knowledge extraction\n- Ontology query API SHALL return results in <50ms (cached)\n- Ontology validation SHALL complete in <20ms per entity\n\n### NFR-2: Scalability\n\n- System SHALL support ontologies with up to 100 entity classes\n- System SHALL support ontologies with up to 50 relationship types\n- System SHALL support up to 10 team-specific lower ontologies\n\n### NFR-3: Maintainability\n\n- Ontology definitions SHALL be in human-readable JSON format\n- Ontology changes SHALL not require code changes\n- System SHALL provide CLI tools for ontology management\n\n### NFR-4: Backward Compatibility\n\n- Existing knowledge without ontology metadata SHALL continue to work\n- System SHALL support gradual migration to ontology-based classification\n- API SHALL maintain compatibility with non-ontology queries\n\n### NFR-5: Extensibility\n\n- System SHALL allow adding new ontology classes without code changes\n- System SHALL allow adding new team ontologies via configuration\n- System SHALL allow extending upper ontology in lower ontologies\n\n---\n\n## 11. Implementation Plan\n\n### Phase 1: Core Infrastructure (Week 1)\n\n**Deliverables**:\n- `OntologyManager.ts` - Load, parse, query ontologies\n- `OntologyValidator.ts` - Validate entities against schema\n- `types.ts` - TypeScript type definitions\n\n**Tasks**:\n1. Create ontology module structure\n2. Implement JSON schema parser\n3. Implement inheritance resolution\n4. Implement validation engine\n5. Write unit tests\n\n### Phase 2: Ontology Definitions (Week 1-2)\n\n**Deliverables**:\n- `upper-cluster-reprocessing.json` - Upper ontology\n- `lower-raas.json` - RaaS team ontology\n- `lower-resi.json` - ReSi team ontology\n- Documentation for ontology structure\n\n**Tasks**:\n1. Define upper ontology entities (25 classes)\n2. Define upper ontology relationships (20 types)\n3. Define RaaS lower ontology (15 classes)\n4. Define ReSi lower ontology (18 classes)\n5. Validate ontology completeness with domain experts\n\n### Phase 3: Classification Integration (Week 2-3)\n\n**Deliverables**:\n- Enhanced `StreamingKnowledgeExtractor.js`\n- `classification-prompts.ts` - LLM prompt templates\n- Updated `KnowledgeStorageService.js`\n\n**Tasks**:\n1. Add ontologyManager to StreamingKnowledgeExtractor\n2. Implement classifyWithOntology() method\n3. Create LLM prompts for ontology classification\n4. Update entity storage with ontology field\n5. Write integration tests\n\n### Phase 4: Query Enhancement (Week 3)\n\n**Deliverables**:\n- Enhanced `GraphDatabaseService.js`\n- Enhanced `KnowledgeRetriever.js`\n- New query methods for ontology-based retrieval\n\n**Tasks**:\n1. Add ontology filtering to queryEntities()\n2. Implement searchByOntologyClass()\n3. Implement findRelatedByOntology()\n4. Add ontology context to semantic search\n5. Write query tests\n\n### Phase 5: Configuration & Testing (Week 4)\n\n**Deliverables**:\n- `ontology-config.json` - Configuration file\n- Comprehensive test suite\n- CLI tools for ontology management\n\n**Tasks**:\n1. Create configuration system\n2. Implement CLI for ontology validation\n3. Implement CLI for ontology visualization\n4. Write E2E tests with real domain knowledge\n5. Performance testing and optimization\n\n### Phase 6: Documentation & Rollout (Week 4-5)\n\n**Deliverables**:\n- User guide for ontology system\n- API reference documentation\n- Migration guide for existing knowledge\n- Team training materials\n\n**Tasks**:\n1. Write ontology user guide\n2. Create API reference docs\n3. Create migration scripts\n4. Conduct team training sessions\n5. Gradual rollout with monitoring\n\n---\n\n## 12. Testing Strategy\n\n### Unit Tests\n- Ontology loading and parsing\n- Inheritance resolution\n- Validation engine\n- Classification logic\n\n### Integration Tests\n- StreamingKnowledgeExtractor with ontology\n- Graph database with ontology metadata\n- Query methods with ontology filters\n\n### End-to-End Tests\n- Real domain knowledge classification\n- Team-specific ontology usage\n- Cross-team knowledge sharing\n\n### Performance Tests\n- Classification overhead measurement\n- Query performance with ontology filters\n- Scalability with large ontologies\n\n### User Acceptance Tests\n- RaaS team validates cloud orchestration ontology\n- ReSi team validates virtual target ontology\n- Domain experts validate upper ontology completeness\n\n---\n\n## 13. Risks & Mitigation\n\n| Risk | Impact | Probability | Mitigation |\n|------|--------|-------------|------------|\n| LLM classification errors | High | Medium | Heuristic fallback, human review queue |\n| Ontology too rigid for evolving domain | High | Low | Extensible schema, easy to add classes |\n| Performance degradation | Medium | Low | Caching, async processing, benchmarking |\n| Team resistance to adoption | Medium | Medium | Optional per team, training, benefits demo |\n| Ontology maintenance overhead | Low | Medium | Clear governance, CLI tools, versioning |\n| Budget exceeded for classification | Medium | Low | Fallback to heuristics, budget monitoring |\n\n---\n\n## 14. Success Metrics\n\n### Adoption Metrics\n- % of knowledge classified with ontology (target: >80%)\n- Number of teams using team-specific ontologies (target: 5 - RaaS, ReSi, Coding, Agentic, UI)\n- Number of ontology-based queries per day (target: >100)\n\n### Quality Metrics\n- Classification accuracy (target: >85%)\n- Validation pass rate (target: >90%)\n- User satisfaction score (target: 4/5)\n\n### Performance Metrics\n- Classification latency (target: <100ms)\n- Query latency (target: <50ms cached, <300ms uncached)\n- System availability (target: >99.5%)\n\n### Business Metrics\n- Time to find relevant knowledge (target: -50%)\n- Cross-team knowledge reuse (target: +30%)\n- Reduction in duplicate knowledge (target: -20%)\n\n---\n\n## 15. Dependencies\n\n### Internal Dependencies\n- StreamingKnowledgeExtractor (existing)\n- GraphDatabaseService (existing)\n- UnifiedInferenceEngine (existing)\n- Configuration system (existing)\n\n### External Dependencies\n- LLM providers (Groq, OpenRouter, Ollama)\n- Domain experts for ontology validation\n- Team coordinators for rollout support\n\n### Technical Dependencies\n- TypeScript 4.9+\n- Node.js 18+\n- JSON Schema validation library\n- Graph database (Graphology + LevelDB)\n\n---\n\n## 16. Acceptance Criteria\n\n### Must Have\n- [ ] Upper ontology covers 80%+ of reprocessing domain concepts\n- [ ] RaaS and ReSi lower ontologies validated by respective teams\n- [ ] Coding, Agentic, and UI lower ontologies cover their respective domains (LSL/constraints, agent frameworks/RAG, multi-agent curriculum system)\n- [ ] StreamingKnowledgeExtractor classifies knowledge using ontology\n- [ ] Graph database stores and queries ontology-enriched entities\n- [ ] Classification adds <100ms overhead\n- [ ] Backward compatibility with non-ontology knowledge maintained\n\n### Should Have\n- [ ] Ontology-based semantic search implemented\n- [ ] CLI tools for ontology management available\n- [ ] Migration script for existing knowledge created\n- [ ] Comprehensive documentation published\n\n### Could Have\n- [ ] Ontology visualization tool created\n- [ ] Automated ontology extension suggestions\n- [ ] Export/import for ontology definitions\n\n---\n\n## 17. Out of Scope\n\n- Integration with external ontology repositories (OWL, SKOS)\n- Automated ontology learning from unstructured text\n- Multi-version ontology support (only single version per team)\n- Real-time collaborative ontology editing\n- Fine-grained access control per ontology class\n\n---\n\n## 18. Glossary\n\n| Term | Definition |\n|------|------------|\n| **Cluster Reprocessing (RPR)** | Ecosystem of tools for replaying vehicle data through virtual targets |\n| **RaaS** | Reprocessing as a Service - cloud orchestration engine (Java, AWS) |\n| **ReSi** | Reprocessing Simulation - virtual target development team (C++, embedded) |\n| **RPU** | Reprocessing Unit - Dockerized virtual target container |\n| **Compound Reprocessing** | Entire sensor + ECU system in execution DAG |\n| **MF4** | Recording format on embedded target (may be fragmented) |\n| **MCAP** | Normalized data processing format (unfragmented) |\n| **Protobuf/SPP** | Serialized Protobuf Protocol payload encoding |\n| **SOME/IP** | Scalable service-Oriented MiddlewarE over IP protocol |\n| **SOTIF** | Safety of the Intended Functionality |\n| **R-DQ** | RaaS Data Quality framework |\n| **FinOps** | Financial Operations and cost optimization |\n| **KPI Framework** | Evaluation triggering layer around RaaS |\n\n---\n\n## 19. References\n\n- StreamingKnowledgeExtractor: `src/knowledge-management/StreamingKnowledgeExtractor.js`\n- GraphDatabaseService: `src/knowledge-management/GraphDatabaseService.js`\n- Continuous Learning System: `docs/knowledge-management/continuous-learning-system.md`\n- Ontology research (from agent): Comprehensive analysis of current system\n\n---\n\n**Document Version**: 1.0\n**Last Updated**: 2025-01-03\n**Author**: AI Assistant (Claude)\n**Approved By**: [Pending]\n**Next Review**: [After Phase 2 completion]\n",
  "fileStats": {
    "size": 48610,
    "lines": 1322,
    "lastModified": "2025-11-04T05:51:41.688Z"
  },
  "comments": []
}