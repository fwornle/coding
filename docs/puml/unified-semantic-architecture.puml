@startuml unified-semantic-architecture
!include _standard-style.puml

title Semantic Analysis & Knowledge Management Architecture

top to bottom direction

package "Clients" {
  [Claude Code] <<external>> as claude
  [GitHub CoPilot] <<external>> as copilot
}

package "API Layer" {
  [MCP Server] <<api>> as mcp
  [HTTP API] <<api>> as http
}

package "Orchestration" #FFFFCC {
  [CoordinatorAgent\nOrchestrates ALL agents] <<agent>> as coord
}

package "Analysis Agents (No LLM)" #E6F3FF {
  [GitHistoryAgent] <<agent>> as git
  [VibeHistoryAgent] <<agent>> as vibe
  [WebSearchAgent] <<agent>> as web
  [ObservationGenerationAgent] <<agent>> as obs
  [PersistenceAgent] <<agent>> as per
}

package "LLM-Powered Agents" #FFE6E6 {
  [SemanticAnalysisAgent] <<agent>> as sem
  [InsightGenerationAgent] <<agent>> as ins
  [QualityAssuranceAgent] <<agent>> as qa
}

package "Infrastructure Agents" #E8F4FD {
  [SynchronizationAgent] <<agent>> as sync
  [DeduplicationAgent] <<agent>> as dedup
}

package "Storage - 3 Sync Targets" {
  database "Graphology DB\nIn-memory graph" <<storage>> as graphdb
  database "knowledge-export/<team>.json\nGit-tracked files" <<storage>> as files
  database "MCP Memory\n(Placeholder)" <<storage>> as mcpmem
}

package "LLM Provider Chain" {
  cloud "Groq\nDefault" <<external>> as groq
  cloud "Gemini\nFallback #1" <<external>> as gemini
  cloud "Custom LLM\nFallback #2" <<external>> as custom
  cloud "Anthropic Claude\nFallback #3" <<external>> as anthropic
  cloud "OpenAI GPT\nFallback #4" <<external>> as openai
}

' Client connections
claude -down-> mcp
copilot -down-> http

' API to coordinator
mcp -down-> coord
http -down-> coord

' Coordinator orchestrates all agents
coord -down-> git
coord -down-> vibe
coord -down-> sem
coord -down-> web
coord -down-> ins
coord -down-> obs
coord -down-> qa
coord -down-> per
coord -down-> sync
coord -down-> dedup

' LLM agents use provider chain
sem ..> groq
sem ..> gemini
sem ..> custom
sem ..> anthropic
sem ..> openai
ins ..> sem : "Delegates"

' Sync agent manages storage
sync -down-> graphdb
sync -down-> files
sync -.-> mcpmem

note right of coord
  **Coordinator orchestrates ALL agents**

  Workflow execution:
  1. Loads workflow definition
  2. Executes steps sequentially
  3. Resolves dependencies
  4. Passes data via {{step.result}}
  5. Returns aggregated results
end note

note right of sync
  **Storage Synchronization**

  Active targets:
  • Graphology DB (in-memory)
  • knowledge-export/ (git)

  Placeholder:
  • MCP Memory (incomplete)

  Bidirectional sync: 60s interval
end note

note right of groq
  **4-Tier LLM Provider Chain**

  Groq → Gemini → Custom → Anthropic → OpenAI

  Used by 2 agents directly:
  • SemanticAnalysisAgent (direct)
  • SemanticAnalyzer (direct)

  Used by 1 agent via delegation:
  • InsightGenerationAgent (via SemanticAnalyzer)

  Models:
  • Groq: llama-3.3-70b-versatile
  • Gemini: gemini-2.0-flash-exp
  • Anthropic: claude-sonnet-4-20250514
  • OpenAI: gpt-4-turbo-preview
end note

@enduml