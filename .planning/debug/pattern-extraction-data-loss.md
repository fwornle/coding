---
status: investigating
trigger: "Investigate why the pattern extraction pipeline shows 93% data loss and cannot confirm parseArchitecturalPatternsFromLLM works in production"
created: 2026-02-27T07:00:00.000Z
updated: 2026-02-27T07:00:00.000Z
---

## Current Focus

hypothesis: The 93% loss is structural - the trace report compares commits+sessions to entities (a category error), while actual entity collapse happens because semantic_analysis produces only 6-11 generic pattern-name entities per batch. parseArchitecturalPatternsFromLLM ran but returned ZERO patterns in this run. The 1778 "patterns" are re-read from existing observation entities, not new LLM extractions.
test: Confirmed via workflow log line 17954 and trace data
expecting: Root cause documented
next_action: COMPLETE - findings written

## Symptoms

expected: 293 concepts should produce meaningful entity output throughout the pipeline
actual: 293 concepts in, 20 entities out (93% data loss). The log line "Extracted 1778 patterns from 1778 observation entities" appears to show rich extraction but is misleading.
errors: No fatal errors - pipeline ran to completion without exceptions
reproduction: Run batch-analysis workflow on the coding team repository
started: This workflow run 2026-02-27T06:03:42Z through 06:32:35Z

## Eliminated

- hypothesis: The data loss happens at deduplication (kg-operators.deduplication)
  evidence: structureMerge and deduplication in kg-operators use name-based exact matching. Deduplication only merges entities with identical normalized names. The loss happens BEFORE deduplication at semantic_analysis where only 6-11 entities are produced per batch.
  timestamp: 2026-02-27T07:00:00Z

- hypothesis: The 1778 patterns represent new LLM extraction in this run
  evidence: Log line 17954 "No structured patterns could be extracted from LLM insights" appears immediately before the 1778 count. The 1778 come from extractPatternsFromObservations() reading already-stored observations, not from LLM analysis.
  timestamp: 2026-02-27T07:00:00Z

- hypothesis: parseArchitecturalPatternsFromLLM failed to run
  evidence: It DID run (line 17948: pattern extraction prompt written, line 17953: result written). The LLM call completed successfully (mock=false, provider=copilot/groq). But the LLM response format could not be parsed by any of the three strategies (JSON, line-based, retry).
  timestamp: 2026-02-27T07:00:00Z

## Evidence

- timestamp: 2026-02-27T07:00:00Z
  checked: trace-batch-analysis-batch-1772172222964 dataLossReport.byStep
  found: ALL data loss is in semantic_analysis step - every batch shows 50-95% loss. observation_generation shows 0% loss. insight_generation shows 0% loss (starts from 0). lossReasons is always empty - the code at ukb-trace-report.ts:776 creates the lossReasons array but never populates it.
  implication: The trace report accurately identifies semantic_analysis as the loss point, but provides zero diagnosis (empty lossReasons).

- timestamp: 2026-02-27T07:00:00Z
  checked: ukb-trace-report.ts:416 - traceSemanticAnalysis() loss calculation
  found: inputCount = gitHistory.commitsCount + vibeHistory.sessionsCount (e.g., batch-001: 47 commits + 0 sessions = 47). outputCount = entities.length (6). This is a category error: the trace compares commits/sessions to entities. A batch with 47 commits that produces 6 entities is not necessarily 87% loss - it is expected compression.
  implication: The "93% data loss" metric in the trace report is MISLEADING. It measures commits-to-entities conversion ratio, not concept coverage. The real question is whether the 6-11 entities per batch are the RIGHT entities.

- timestamp: 2026-02-27T07:00:00Z
  checked: coordinator.ts:2634 - analyzeGitAndVibeData() call
  found: The semantic analysis agent receives {commits: [...47 commits...], architecturalDecisions: [], codeEvolution: []} and session data. It returns a SemanticAnalysisResult with codeAnalysis.architecturalPatterns, NOT a list of entities.
  implication: The semantic_analysis step is not intended to produce one entity per commit. It produces code patterns found in analyzed files. The number of output entities is bounded by the number of distinct patterns found, not by the number of commits.

- timestamp: 2026-02-27T07:00:00Z
  checked: semantic-analysis-agent.ts:494-547 - generateCodeAnalysisMetrics() and getPatternDescription()
  found: Architectural patterns are generated by scanning code files for 10 hardcoded pattern keywords: singleton, factory, observer, promise, decorator, middleware, repository, service, component, api. The getPatternDescription() function maps these to fixed descriptions. This is pure regex matching - no LLM involved.
  implication: The 6-11 entities per batch are always drawn from this fixed 10-pattern vocabulary. The same patterns repeat in every batch. This explains why the final KG has only 20 unique entities - the vocabulary is small and deduplication collapses all 30 batches into the same 10 patterns.

- timestamp: 2026-02-27T07:00:00Z
  checked: workflow log lines 12373-12410 - persistEntities call
  found: All 20 entities being persisted are pre-existing entities (exact match FOUND for all but one). The one new entity is KnowledgemanagementsystemarchitectureDecisionImplementComprehensive - derived from an LLM-synthesized observation. The pipeline is updating observations on existing KG entries, not creating new entities.
  implication: The KG already had the 10 pattern-vocabulary entities from previous runs. This run added observations to them but created virtually no net-new entities.

- timestamp: 2026-02-27T07:00:00Z
  checked: workflow log lines 17942-17956 - insight generation sequence
  found: Line 17947: "Code graph analysis was skipped: code-graph-rag directory not found". Line 17948: pattern extraction prompt written. Line 17953: result written (LLM call completed). Line 17954: "No structured patterns could be extracted from LLM insights". Line 17955: "Extracted 1778 patterns from 1778 observation entities". Line 17956: "Extracted 1778 patterns from 1778 observations".
  implication: parseArchitecturalPatternsFromLLM ran. The LLM call completed. But the response format did not match any of the 3 parsing strategies. The 1778 patterns come ENTIRELY from extractPatternsFromObservations() reading accumulated batch observations.

- timestamp: 2026-02-27T07:00:00Z
  checked: insight-generation-agent.ts:4169-4215 - extractPatternsFromObservations()
  found: This function creates one IdentifiedPattern per observation entity from allBatchObservations accumulated during 30 batches. Each batch generated approximately 59 observations on average (1778 / 30). All patterns use names from the 10-pattern vocabulary: ApiHandlesExternalCommunication, PromiseHandlesAsynchronousOperations, etc.
  implication: The 1778 patterns are near-duplicates. When sorted by significance, the top 20 are the highest-significance copies of 6-8 unique concept names.

- timestamp: 2026-02-27T07:00:00Z
  checked: workflow log lines 17967-17977 - top 10 patterns by significance
  found: ApiHandlesExternalCommunication appears 4 times in the top 10. PromiseHandlesAsynchronousOperations appears 6 times. These are identical concept names appearing repeatedly from different batches.
  implication: Confirms vocabulary lock-in. The insight generation is processing 1778 near-identical copies of 10 patterns. The top 20 selected for insight documents are random duplicates of the same few concepts.

- timestamp: 2026-02-27T07:00:00Z
  checked: insight-generation-agent.ts:3775-3848 - extractArchitecturalPatternsFromCommits() LLM logic
  found: The prompt is correctly sent to the LLM with a summary of up to 100 commits. The LLM returns a response (analysisResult.insights is non-null as confirmed by line 17953). parseArchitecturalPatternsFromLLM then exhausts all 3 strategies without extracting patterns. The actual LLM response content is inside Docker container (/coding/logs/pattern-extraction-result-1772173623377.json) and not accessible from the host. Previous run trace files (pattern-extraction-result-1769877223136.json) show the LLM produces "### 1. **PatternName**" format which should match Strategy 2a.
  implication: parseArchitecturalPatternsFromLLM IS called in production. The parsing failure in this run may be due to: a different LLM response format from a different provider in the chain, or the response being empty/truncated due to the larger input size (1115 commits, first 100 used).

- timestamp: 2026-02-27T07:00:00Z
  checked: insight-generation-agent.ts:3966-3970 - zero pattern warning
  found: When all strategies fail, the code logs "No structured patterns could be extracted from LLM insights (all strategies exhausted)" with llmInsightsLength and commitCount but NOT the actual LLM response text. This makes diagnosis impossible from logs alone.
  implication: The actual LLM response content needs to be logged (at least first 500 chars) when parsing fails, otherwise the root cause of parseArchitecturalPatternsFromLLM returning 0 cannot be determined post-hoc.

## Resolution

root_cause: |
  The 93% "data loss" has four distinct root causes:

  ROOT CAUSE 1 - Misleading metric definition (ukb-trace-report.ts:416):
  The semantic_analysis "loss" metric compares (git commits + vibe sessions)
  to output entities. This is a category error. Commits are raw inputs;
  entities are compressed semantic abstractions. A batch of 47 commits
  that produces 6 entities is correct behavior, not 87% loss. The real
  question is whether the 6 entities are representative.

  ROOT CAUSE 2 - Entity vocabulary is hardcoded to 10 patterns (semantic-analysis-agent.ts:532-547):
  Every batch scans code files for 10 hardcoded keywords and generates
  entities only from those. After 30 batches of identical vocabulary,
  deduplication correctly collapses all to ~10-20 unique entities.
  Phase 01's parseArchitecturalPatternsFromLLM only runs during finalization
  insight generation - it does NOT feed back into per-batch entity creation.
  This is the primary structural cause of low entity diversity.

  ROOT CAUSE 3 - parseArchitecturalPatternsFromLLM returned 0 patterns (this run):
  The function ran. The LLM call completed. The response could not be parsed
  by any of the three strategies. The actual response content is inaccessible
  (inside Docker). Even in successful runs, the extracted patterns only create
  insight documents, NOT new KG entities - so fixing this would not change
  the 20-entity KG output.

  ROOT CAUSE 4 - The "1778 patterns" log is misleading:
  extractPatternsFromObservations() re-reads all accumulated batch observations.
  These are 1778 copies of the same ~10 vocabulary names from 30 batches.
  The significance sort picks the highest-significance duplicates (not the
  most diverse patterns) for insight generation.

fix: Research only - no fix applied
verification: N/A
files_changed: []

---

## FULL DATA FLOW MAP

### Stage 1: Git History to Batches

- Input: 1115 commits, 1275 vibe sessions, 8426 code files
- batch-scheduler.ts divides into 30 batches of approximately 37 commits each
- batch-001: 47 commits, batch-030: 13 commits (varies)

### Stage 2: Per-Batch Semantic Analysis (x30)

Step: extract_batch_commits
- Output: git commits for this batch with file change lists

Step: extract_batch_sessions
- Output: vibe sessions correlated with commits by date range

Step: batch_semantic_analysis (coordinator.ts:2595-2782)
- semantic-analysis-agent.analyzeGitAndVibeData() is called with:
  - gitAnalysis: {commits: [...], architecturalDecisions: [], codeEvolution: []}
  - vibeAnalysis: {sessions: [...], problemSolutionPairs: [], patterns: {}}
  - options: {analysisDepth: 'deep'}
- Inside analyzeGitAndVibeData():
  - extractFilesFromGitHistory() extracts up to 100 files from commit diffs
  - analyzeCodeFiles() reads file content from disk
  - generateCodeAnalysisMetrics() scans file content for 10 hardcoded patterns
  - generateSemanticInsights() makes one LLM call for key patterns and decisions
  - Returns: SemanticAnalysisResult (analysis data, NOT entities)
- observation-generation-agent.generateStructuredObservations() is called with:
  - enrichedGitAnalysis (architecturalDecisions + codeEvolution from semantic result)
  - insightsForObservation (architecturalPatterns from semantic result)
  - Output: 10-18 observations with names derived from the 10-pattern vocabulary
- Entity transform: observations -> KGEntity[] (6-11 entities per batch)
  - All entity names come from the 10-pattern vocabulary

Step: ontology_classification
- Classifies entity types (KnowledgeEntity, Contract, etc.)

Step: kg_operators (per batch)
- CONV: context enrichment with batch date range and related commits
- AGGR: core/non-core role assignment by significance
- EMBED: deterministic word-level vector embeddings
- DEDUP: exact normalized-name merge with accumulatedKG
  - After batch 6, accumulatedKG stabilizes at approximately 20 unique entities
  - All subsequent batches deduplicate into the same entity set
- PRED: edge prediction using cosine similarity scoring
- MERGE: structureMerge into accumulatedKG

### Stage 3: Finalization

Step: final_persist (persistence-agent)
- Input: accumulatedKG.entities = 20 entities
- getEntity() finds exact matches for 19 of 20 entities (pre-existing)
- Updates observations on existing KG entries
- Creates 1 net-new entity

Step: INSIGHT GENERATION (coordinator.ts:3865)
- insightAgent.generateComprehensiveInsights() is called with:
  - git_analysis_results: {commits: all 1115 commits}
  - observations: allBatchObservations (1778 observation objects from 30 batches)
  - (code_graph_results: SKIPPED - code-graph-rag directory not found)
- generatePatternCatalog() calls extractArchitecturalPatternsFromCommits(1115 commits):
  - Filters to first 100 commits
  - Sends LLM prompt via semanticAnalyzer.analyzeContent()
  - parseArchitecturalPatternsFromLLM() is called on LLM response
  - In THIS run: all 3 parsing strategies returned 0 patterns
  - extractPatternsFromObservations(allBatchObservations = 1778) is called:
    - Returns 1778 patterns (one per observation entity)
    - All named from the 10-pattern vocabulary
- significance filter: all 1778 pass (significance >= 5)
- Top 20 selected by significance (duplicates of 6-8 unique names)
- generateInsightDocuments() creates 21 insight documents for top patterns

### Final Output

- KG entities: 20
- KG relations: 21
- Insight documents: 21

---

## ANSWERS TO INVESTIGATION QUESTIONS

### Question 1: Is parseArchitecturalPatternsFromLLM actually called?

YES. It is called every run during finalization insight generation.

Call chain:
- coordinator.ts:3865 insightAgent.generateComprehensiveInsights(params)
- insight-generation-agent.ts:681 generatePatternCatalog(...)
- insight-generation-agent.ts:988 extractArchitecturalPatternsFromCommits(commits)
- insight-generation-agent.ts:3813 semanticAnalyzer.analyzeContent(prompt, ...)
  - [LLM API call completes successfully]
- insight-generation-agent.ts:3833 parseArchitecturalPatternsFromLLM(analysisResult.insights, commits)

In this specific run, the LLM call returned a response but the format did not match
any of the 3 parsing strategies (JSON parse, line-based markdown, format-hint retry).
The function returned 0 patterns. The actual LLM response is in the Docker container
at /coding/logs/pattern-extraction-result-1772173623377.json (not accessible on host).

### Question 2: Where exactly does the 93% data loss happen?

The loss is structural across multiple stages, not a single failure point:

Stage A - semantic_analysis per batch (87-95% per batch):
- Input: 20-162 (commits + sessions counted by trace - category error)
- Output: 6-11 entities
- True cause: Entity vocabulary is hardcoded to 10 pattern keywords.
  Every batch can only produce entities named after those 10 keywords.

Stage B - cross-batch deduplication (collapses all batches):
- After approximately batch 6, accumulatedKG stabilizes at ~20 unique entities
- Remaining 24 batches just add observations to the same entities
- This is CORRECT behavior for name-based deduplication - the problem is upstream

Stage C - parseArchitecturalPatternsFromLLM failure (this run only):
- The LLM extracted 0 patterns due to unparseable response format
- Even if it had worked, the output creates insight documents only, not new KG entities

Stage D - insight generation processes 1778 duplicates:
- extractPatternsFromObservations re-reads accumulated observations
- 1778 near-identical copies of ~10 entity names are passed through significance filter
- Top 20 for insight generation are duplicates of the same 6-8 concepts

### Question 3: What is the actual flow of data?

Fully documented in the DATA FLOW MAP section above.

Summary: git commits -> batches -> semantic analysis (10-pattern regex scan) ->
observations -> entities (6-11/batch, all from same 10 names) ->
kg_operators dedup (collapses to ~20 unique) -> persist (20 entities) ->
insight generation (re-reads 1778 observation duplicates, ignores failed LLM extraction)
