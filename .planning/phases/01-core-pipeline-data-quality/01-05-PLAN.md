---
phase: 01-core-pipeline-data-quality
plan: 05
type: execute
wave: 2
depends_on: [03, 04]
files_modified:
  - integrations/mcp-server-semantic-analysis/src/agents/semantic-analysis-agent.ts
  - integrations/mcp-server-semantic-analysis/src/utils/ukb-trace-report.ts
autonomous: true
gap_closure: true
requirements: [PTRN-01, PTRN-02, DATA-03]

must_haves:
  truths:
    - "Per-batch semantic analysis uses LLM-identified patterns instead of only 10 hardcoded regex patterns"
    - "Entity diversity increases beyond the 10-pattern vocabulary ceiling"
    - "Trace report loss metric compares semantically equivalent units, not commits to entities"
    - "Trace report insightGeneration populates materialsUsed from actual InsightDocument data"
  artifacts:
    - path: "integrations/mcp-server-semantic-analysis/src/agents/semantic-analysis-agent.ts"
      provides: "LLM-driven pattern enrichment in generateCodeAnalysisMetrics"
      contains: "architecturalPatterns"
    - path: "integrations/mcp-server-semantic-analysis/src/utils/ukb-trace-report.ts"
      provides: "Fixed loss metric and materialsUsed population"
      contains: "conceptsExtracted"
  key_links:
    - from: "generateCodeAnalysisMetrics"
      to: "generateSemanticInsights"
      via: "LLM-identified patterns merged into architecturalPatterns"
      pattern: "architecturalPatterns.*push|concat"
    - from: "traceSemanticAnalysis"
      to: "trackDataLoss"
      via: "conceptsExtracted count instead of commits count"
      pattern: "conceptsExtracted|entitiesCreated"
---

<objective>
Replace the hardcoded 10-pattern vocabulary in per-batch semantic analysis with LLM-enriched pattern extraction, and fix the misleading trace report metrics.

Purpose: The root cause of low entity diversity is that generateCodeAnalysisMetrics() in semantic-analysis-agent.ts scans for only 10 hardcoded regex patterns (singleton, factory, observer, etc.). After 30 batches, deduplication collapses everything to ~20 entities. The LLM already analyzes the code in generateSemanticInsights() -- we need to extract the patterns it identifies and merge them into the architecturalPatterns result. The trace report also needs fixing: it compares commits-to-entities (category error) and hardcodes materialsUsed to empty arrays.

Output: Richer entity diversity per batch and accurate trace metrics.
</objective>

<execution_context>
@/Users/Q284340/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Q284340/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-pipeline-data-quality/01-01-SUMMARY.md
@.planning/phases/01-core-pipeline-data-quality/01-02-SUMMARY.md
@.planning/debug/pattern-extraction-data-loss.md

<interfaces>
<!-- semantic-analysis-agent.ts key interfaces: -->

```typescript
// detectCodePatterns (line 384) - returns string[] of 10 hardcoded pattern names
private detectCodePatterns(content: string, language: string): string[]

// generateCodeAnalysisMetrics (line 474) - aggregates patterns from all code files
// Returns architecturalPatterns array with {name, files, description, confidence}
private generateCodeAnalysisMetrics(codeFiles: CodeFile[]): SemanticAnalysisResult['codeAnalysis']

// getPatternDescription (line 532) - maps 10 hardcoded names to descriptions
private getPatternDescription(pattern: string): string

// generateSemanticInsights (line ~600) - makes LLM call, returns keyPatterns, decisions, evolution
// The LLM response already contains identified patterns but they are NOT fed back into architecturalPatterns
private async generateSemanticInsights(...)
```

<!-- ukb-trace-report.ts key interfaces: -->

```typescript
// traceSemanticAnalysis (line 393) - tracks per-batch analysis
// BUG: inputItems = commits + sessions (should be concepts/patterns extracted)
traceSemanticAnalysis(batchId: string, semanticResult: any, llmProvider: string, tokensUsed: number): void

// traceInsightGeneration (line 549) - tracks finalization insights
// BUG: materialsUsed hardcoded to empty arrays, qualityScore defaults to 0
traceInsightGeneration(insightResult: any): void
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enrich architecturalPatterns with LLM-identified patterns in semantic-analysis-agent.ts</name>
  <files>integrations/mcp-server-semantic-analysis/src/agents/semantic-analysis-agent.ts</files>
  <action>
The semantic analysis agent already calls the LLM via generateSemanticInsights() which returns keyPatterns (LLM-identified patterns from the code). Currently these keyPatterns are included in the SemanticAnalysisResult but NOT merged into the architecturalPatterns from generateCodeAnalysisMetrics(). The fix is to merge them.

**Step 1: Find where generateSemanticInsights result is used.**
Look for the call site of generateSemanticInsights() -- it should be in the main analysis method (analyzeGitAndVibeData or similar). Find where its result (specifically the keyPatterns/patterns field) is available alongside the codeAnalysis from generateCodeAnalysisMetrics().

**Step 2: After generateSemanticInsights() returns, merge LLM-identified patterns into codeAnalysis.architecturalPatterns.**

Find the point where both codeAnalysis (from generateCodeAnalysisMetrics) and semanticInsights (from generateSemanticInsights) are available. Add code to merge LLM patterns:

```typescript
// Enrich architectural patterns with LLM-identified patterns
// The LLM sees the actual code and identifies real patterns beyond the 10 hardcoded ones
const llmPatterns = semanticInsights?.keyPatterns || semanticInsights?.patterns || [];
if (Array.isArray(llmPatterns) && llmPatterns.length > 0) {
  const existingNames = new Set(codeAnalysis.architecturalPatterns.map(p => p.name.toLowerCase()));
  for (const llmPattern of llmPatterns) {
    const patternName = typeof llmPattern === 'string' ? llmPattern : (llmPattern.name || llmPattern.pattern || '');
    const patternDesc = typeof llmPattern === 'string' ? '' : (llmPattern.description || '');
    if (patternName && !existingNames.has(patternName.toLowerCase())) {
      codeAnalysis.architecturalPatterns.push({
        name: patternName,
        files: [],  // LLM doesn't provide file-level mapping
        description: patternDesc || `${patternName} - identified by LLM analysis`,
        confidence: typeof llmPattern === 'object' ? (llmPattern.confidence || 0.7) : 0.7
      });
      existingNames.add(patternName.toLowerCase());
    }
  }
  log(`Enriched architectural patterns: ${codeAnalysis.architecturalPatterns.length} total (${llmPatterns.length} from LLM)`, 'info');
}
```

**Important constraints:**
- Do NOT modify detectCodePatterns() or getPatternDescription() -- they still provide a baseline
- Do NOT modify generateSemanticInsights() -- it already works
- ONLY add the merge logic at the point where both results are available
- Keep the existing regex-based patterns as a baseline; LLM patterns ADD to them
- Deduplicate by lowercase name to avoid duplicates between regex and LLM patterns
- If the LLM returned zero patterns (or the field is missing), the baseline 10 patterns still work

**Step 3: Verify the SemanticAnalysisResult type allows additional patterns.**
Check the type definition for architecturalPatterns -- it should be an array that allows push(). If it's readonly, cast or use spread to create a new array.

After editing, verify TypeScript compiles:
```bash
cd integrations/mcp-server-semantic-analysis && npx tsc --noEmit 2>&1 | grep 'error TS' | head -10
```
  </action>
  <verify>
    <automated>grep -c 'llmPatterns\|Enriched architectural' integrations/mcp-server-semantic-analysis/src/agents/semantic-analysis-agent.ts</automated>
  </verify>
  <done>LLM-identified patterns from generateSemanticInsights are merged into architecturalPatterns, enriching per-batch entity extraction beyond the 10-pattern regex vocabulary. Existing regex baseline preserved as fallback.</done>
</task>

<task type="auto">
  <name>Task 2: Fix trace report loss metric and materialsUsed in ukb-trace-report.ts</name>
  <files>integrations/mcp-server-semantic-analysis/src/utils/ukb-trace-report.ts</files>
  <action>
Fix two issues in the trace report:

**Fix A - traceSemanticAnalysis loss metric (line ~416):**

Current code compares commits+sessions to entities (category error):
```typescript
const inputItems = batch.sourceData.gitHistory.commitsCount + batch.sourceData.vibeHistory.sessionsCount;
this.trackDataLoss(batch, 'semantic_analysis', inputItems, entities.length);
```

The semantic analysis step transforms code files into patterns/entities. The input count should reflect what the analysis actually processes (code files or extracted concepts), not raw git commits. Change to:
```typescript
// Use the number of concepts/patterns extracted as the input metric,
// not raw commits (which are a different abstraction level)
const conceptsExtracted = (semanticResult?.codeAnalysis?.architecturalPatterns?.length || 0)
  + (semanticResult?.codeAnalysis?.filesAnalyzed || 0);
const inputDescription = `${semanticResult?.codeAnalysis?.filesAnalyzed || 0} files analyzed, ${semanticResult?.codeAnalysis?.architecturalPatterns?.length || 0} patterns found`;
this.trackDataLoss(batch, 'semantic_analysis', conceptsExtracted, entities.length);
log(`[UKBTraceReport] Batch ${batchId}: ${inputDescription} -> ${entities.length} entities`, 'info');
```

If trackDataLoss requires the old field name format, check its signature and adapt. The key change is: input should be files+patterns (what semantic analysis processes), not commits (what git history provides).

**Fix B - traceInsightGeneration materialsUsed (line ~554):**

Current code hardcodes all fields to empty. Populate from available InsightDocument data:
```typescript
this.report.finalization!.insightGeneration = insights.map((i: any) => ({
  entityName: i.name || 'unknown',
  materialsUsed: {
    observations: i.observations?.length ? i.observations.slice(0, 5).map((o: any) => typeof o === 'string' ? o.substring(0, 100) : (o?.content || '').substring(0, 100)) : [],
    commits: i.relatedCommits || i.metadata?.commits || [],
    sessions: i.relatedSessions || i.metadata?.sessions || [],
    codeSnippets: i.codeExamples?.slice(0, 3) || [],
    patterns: i.patterns?.map((p: any) => typeof p === 'string' ? p : p.name) || i.metadata?.tags || []
  },
  insightDocument: {
    title: i.title || '',
    filePath: i.filePath || '',
    sections: i.sections?.map((s: any) => s.title || s.name || '') || [],
    diagramsGenerated: i.diagrams?.map((d: any) => d.type || d.name || '') || []
  },
  significance: i.significance || 5,
  qualityScore: i.qualityScore || i.metadata?.qualityScore || 0
}));
```

The key change: attempt to read materialsUsed fields from the InsightDocument object. If the fields are not present on the object (likely), the `|| []` fallback still provides empty arrays -- but now if InsightDocument IS enhanced in the future, the trace will pick it up automatically.

Also check if `i.content` is available and add a `contentLength` field if it exists:
```typescript
contentLength: (i.content || '').length,  // Track that content was actually generated
```
  </action>
  <verify>
    <automated>cd /Users/Q284340/Agentic/coding && grep -c 'conceptsExtracted\|filesAnalyzed\|contentLength' integrations/mcp-server-semantic-analysis/src/utils/ukb-trace-report.ts</automated>
  </verify>
  <done>Trace report loss metric uses files+patterns (not commits) as the input count for semantic_analysis step. materialsUsed populated from available InsightDocument fields instead of hardcoded empty arrays. qualityScore reads from metadata if available.</done>
</task>

</tasks>

<verification>
1. `grep 'llmPatterns\|Enriched architectural' integrations/mcp-server-semantic-analysis/src/agents/semantic-analysis-agent.ts` confirms LLM pattern merge logic exists
2. `grep 'conceptsExtracted\|filesAnalyzed' integrations/mcp-server-semantic-analysis/src/utils/ukb-trace-report.ts` confirms metric fix
3. `grep -c 'materialsUsed' integrations/mcp-server-semantic-analysis/src/utils/ukb-trace-report.ts` still returns 2+ (the field exists but is now populated)
4. `cd integrations/mcp-server-semantic-analysis && npx tsc --noEmit 2>&1 | grep 'error TS' | wc -l` shows no new TypeScript errors
</verification>

<success_criteria>
- Per-batch semantic analysis merges LLM-identified patterns into architecturalPatterns alongside the regex baseline
- Entity vocabulary is no longer limited to 10 hardcoded names
- Trace report loss metric uses files+patterns as input, not raw commits
- Trace report materialsUsed reads from InsightDocument fields instead of hardcoding empty arrays
- No new TypeScript compilation errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-pipeline-data-quality/01-05-SUMMARY.md`
</output>
